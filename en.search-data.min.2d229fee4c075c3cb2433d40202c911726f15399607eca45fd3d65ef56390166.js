'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/Table-of-contents/0.-Preface/','title':"0. Preface",'content':"What are Hybrid networks, anyway? #  While looking through the web, it seemed there is no clear-cut definition of \u0026ldquo;Hybrid\u0026rdquo;.\n  This Qiskit tutorial uses a classical Neural network to learn the optimal rotations for a simple quantum circuit.\n  This Tensorflow Quantum tutorial uses something akin to a regular max-pooling layer to first downproject the 28x28 images to 4x4 images, which are then fed into a qubit grid of same size.\n  One notable difference here being, whether the data is explicitly embedded into a quantum state, or if rotatations on a fixed initial state are optimized, representing the data implicitly.\n  Benedetti et al. define it in the following way:\n \u0026ldquo;Within the hybrid system, the quantum computer prepares quantum states according to a set of parameters. Using the measurement outcomes, the classical learning algorithm adjusts the parameters in order to minimize an objective function. The updated parameters, now defining a new quantumcircuit, are fed back to the quantum hardware in a closed loop.\u0026ldquo; 2\n Wikipedia introduces the distinction based on what realm of data is processed with which algorithm:\n  So, I guess in the end, any system that TODO\nSources #  1: arXiv:2003.09887  2: arXiv:1906.07682  https://commons.wikimedia.org/wiki/File:Qml_approaches.tif\n"});index.add({'id':1,'href':'/docs/Table-of-contents/1.-Introduction/','title':"1. Introduction",'content':"Environment setup #  There is actually a suprisingly large amount of different libraries for quantum state simulation. I will use pennylane by XANADU.\nQiskit\nTensorflow Quantum\nCirq\nVirtual env #  "});index.add({'id':2,'href':'/docs/Table-of-contents/2.-The-Data/','title':"2. the Data",'content':"About the Data #  This synthetic set consists of three subsets, each with three increasing difficulty levels, amounting to 9 datasets in total. Each of the nine sets consists of 1500 points (the amount is specified during the data generation). The data are split into 70% train and 30% validation.\n  Screenshot from  1\n*Note that the Datasets are nomalized to length one, but not centered around zero. To me it is unclear why that has not been done.\nSometimes the individual sets might be referenced as \u0026lsquo;1b\u0026rsquo; or \u0026lsquo;3c\u0026rsquo;, where the rows are indexed alphabetically top to bottom and the columns are numbered left to right.\nIn the following picture you can see the recreated data:\n  *Note that the exact coloring might not match with the originals, this does not matter as training is done seperately.\nIn 1a one can see the only overlapping and not linearly seperable dataset. Within the first row, there is an increase in the number of clusters and in thier respective bias towards the center. 1b is also imbalanced.\nThe second row shows a steady increase in number of clusters, with the middle one also being imbalanced.\nThe final row consists of enclosed and imbalanced datasets throughout, again with the number of clusters increasing left to right.\nSources #  1: arXiv:2003.09887 \n"});index.add({'id':3,'href':'/docs/Table-of-contents/3.-Embedding/','title':"3. Embedding",'content':"How does one get the data into the Quantum circuit? #  There are a multitude of ways to do so. The two simplest ways to embed information are Amplitude and Product encoding.\nAmplitude encoding #  Amplitude encoding only works if the input features x are nomalized to   \\(\\bm{x} \\in [0,1] \\)  . Then the Quantum states are prepared as following:\nAmplitude encoding\n \\( x \\in\\{0,1\\}^{n} \\rightarrow |x \\rangle \\)   This of cause also works when working with binary input features, then it is called Basis encoding Amplitude embedding gives rise to a linear kernel in feature Hilbert space 3 and while it is consideres memory efficient, unfortunately ,the depth of this encoder circuit is expected to scale ex-ponentially with the number of qubits for generic inputs.Therefore, algorithms based on amplitude encoding couldbe impeded by our inability to coherently load data intoquantum states. 2\nProduct encoding #  Here, the initial states of the qubits are fixed, e.g. to  \\(|0\\rangle\\)  TODO\nProduct encoding\n \\( x \\in \\mathbb{R}^{N} \\rightarrow\\left|\\psi_{x}\\right\\rangle=\\cos \\left(x_{j}\\right)|0\\rangle\u0026#43;\\sin \\left(x_{j}\\right)|1\\rangle \\)   Embedding circuit #    Code #  @qml.template def statepreparation(x): qml.RX(x[0], wires=0) qml.RX(x[1], wires=1) qml.RX(x[0], wires=2) qml.RX(x[1], wires=3) qml.RY(np.pi / 4, wires=0) qml.RY(np.pi / 4, wires=1) qml.RY(np.pi / 4, wires=2) qml.RY(np.pi / 4, wires=3) qml.RZ(np.pi / 4, wires=0) qml.RZ(np.pi / 4, wires=1) qml.RZ(np.pi / 4, wires=2) qml.RZ(np.pi / 4, wires=3) Sources #  2: arXiv:1906.07682  3: Quantum machine learning in feature Hilbert spaces \n"});index.add({'id':4,'href':'/docs/Table-of-contents/4.-Parametrized-Quantum-Circuit/','title':"4. Parametrized Quantum Circuit",'content':"Ubi loqui #  Markdown\n  \\(Q\\)   "});index.add({'id':5,'href':'/docs/Table-of-contents/5.-Measurement/','title':"5. Measurement",'content':"Ubi loqui #  Markdown\n  \\(Q\\)   "});index.add({'id':6,'href':'/docs/Table-of-contents/6.-Mapping/','title':"6. Mapping",'content':"Ubi loqui #  Markdown\n  \\(Q\\)   "});index.add({'id':7,'href':'/docs/Table-of-contents/7.-Loss/','title':"7. Loss",'content':"Ubi loqui #  Markdown\n  \\(Qz\\)   "});index.add({'id':8,'href':'/docs/Table-of-contents/8.-Optimization/','title':"8. Optimization",'content':"Ubi loqui #  Markdown\n  \\(Q \\)   "});index.add({'id':9,'href':'/docs/Table-of-contents/','title':"Table of Contents",'content':""});index.add({'id':10,'href':'/docs/','title':"Docs",'content':""});})();