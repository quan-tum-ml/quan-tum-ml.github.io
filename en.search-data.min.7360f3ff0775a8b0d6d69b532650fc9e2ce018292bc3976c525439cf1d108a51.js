'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/Table-of-contents/0.-Preface/','title':"0. Preface",'content':"What are Hybrid networks, anyway? #  While looking through the web, it seemed there is no clear-cut definition of \u0026ldquo;Hybrid\u0026rdquo;.\n  This Qiskit tutorial uses a classical Neural network to learn the optimal rotations for a simple quantum circuit.\n  This Tensorflow Quantum tutorial uses something akin to a regular max-pooling layer to first down project the 28x28 images to 4x4 images, which are then fed into a qubit grid of same size.\n  One notable difference here being, whether the data is explicitly embedded into a quantum state, or if rotations on a fixed initial state are optimized, representing the data implicitly.\n  Benedetti et al. define it in the following way:\n \u0026ldquo;Within the hybrid system, the quantum computer prepares quantum states according to a set of parameters. Using the measurement outcomes, the classical learning algorithm adjusts the parameters in order to minimize an objective function. The updated parameters, now defining a new quantum circuit, are fed back to the quantum hardware in a closed loop.\u0026ldquo; 2\n Wikipedia introduces the distinction based on what realm of data is processed with which algorithm:\n  So, I guess in the end, any system that either\n works with classical data on some quantum hardware, or works with quantum data on classical hardware, or uses classical data-processing layers in conjunction with quantum layers, or uses a quantum system with a classical optimizer \u0026hellip; can be considered \u0026ldquo;hybrid-quantum-classical systems\u0026rdquo;  Sources #  1: Evaluation of Parameterized Quantum Circuits: on the design, and the relation between classification accuracy, expressibility and entangling capability, arXiv:2003.09887  2: Parameterized quantum circuits as machine learning models, arXiv:1906.07682 \n"});index.add({'id':1,'href':'/docs/Table-of-contents/1.-Introduction/','title':"1. Introduction",'content':"Environment setup #  There is actually a surprisingly large amount of different libraries for quantum state simulation. I will use pennylane by XANADU.\n    Pennylane has a clear focus on optimization and machine learning, but also hat tutorials on quantum chemistry. Pennylane interfaces with Pytorch, Tensorflow and even Qiskit. One can import qiskit circuits or use Tensorflow/Pytorch optimizers. Pretty neat.\nThat being said, theoretically one could also use some oth the other libraries, here is a short, no-exaustive list:\n  Qiskit  Tensorflow Quantum  Cirq  Qaintum  Virtual env #  It is recommended to set up a virtual environment, e.g. using Anaconda. To create a virtual environment and install the necessary packages:\nconda create --name quantum source activate quantum pip install qiskit scipy jupyter numpy matplotlib pennylane Getting started #  Fire up a Jupyter Notebook and you are good to go! For starters, have a look at the pennylane tutorials scetion!\n"});index.add({'id':2,'href':'/docs/Table-of-contents/2.-The-Data/','title':"2. the Data",'content':"About the Data #  This synthetic set consists of three subsets, each with three increasing difficulty levels, amounting to 9 data sets in total. Each of the nine sets consists of 1500 points (the amount is specified during the data generation). The data are split into 70% train and 30% validation.\n  Screenshot from  1\n*Note that the data sets are normalized to length one, but not centered around zero. To me it is unclear why that has not been done.\nSometimes the individual sets might be referenced as \u0026lsquo;1b\u0026rsquo; or \u0026lsquo;3c\u0026rsquo;, where the rows are indexed alphabetically top to bottom and the columns are numbered left to right.\nIn the following picture you can see the recreated data:\n  *Note that the exact coloring might not match with the originals, this does not matter as training is done separately.\nIn 1a one can see the only overlapping and not linearly separable data set. Within the first row, there is an increase in the number of clusters and in their respective bias towards the center. 1b is also imbalanced.\nThe second row shows a steady increase in number of clusters, with the middle one also being imbalanced.\nThe final row consists of enclosed and imbalanced data sets throughout, again with the number of clusters increasing left to right.\nSources #  1: Evaluation of Parameterized Quantum Circuits: on the design, and the relation between classification accuracy, expressibility and entangling capability, arXiv:2003.09887 \n"});index.add({'id':3,'href':'/docs/Table-of-contents/3.-Architecture/','title':"3. Architecture",'content':"Architecture #  Quantum Circuit #  I shall quickly describe the individual components which will be explained in greater detail on the following pages. Here the hybrid aspect becomes obvious: Blue background represents a quantum computer based system, while gray background represents a classical computer system.\n   The Data: synthetic, two-dimensional data, normalized and centered. Embedding: encodes the data into quantum states. Parameterized Quantum Circuit: Performs rotations and controlled rotations on qubits according to the parameter vector theta. Measurement: measures the quantum states in classical bits. Mapping: maps the probability distribution obtained my measuring to binary labels. Loss function: computes the difference between output and ground-truth according to some distance measure. Optimizer: minimizes the loss function by changing the parameter vector theta.  Neural Network #  For completenes\u0026rsquo; sake and for comparison, here is also the architecture of the two layer Neural Network: Again, the gray background represents a classical computer system. While there is no 1:1 correspondence between most components, similar colors were chosen.\n   The Data: synthetic, two-dimensional data, normalized and centered. (Same as above) Neural Network: Has two input and one output feature. Consists of two fully connected layers, which apply weights and biases according to some input vector. The non-linear activation function is a RELU function. Loss function: computes the difference between output and ground-truth according to some distance measure. (Same as above) Optimizer: minimizes the loss function by changing weights and biases.  "});index.add({'id':4,'href':'/docs/Table-of-contents/4.-Embedding/','title':"4. Embedding",'content':"How does one get the data into the Quantum circuit? #  There are a multitude of ways to do so. The two simplest ways to embed information are Amplitude and Product encoding. This embedding circuit precedes all other quantum circuits shown later and will not be drawn explicitly.\nAmplitude encoding #  Amplitude encoding only works if the input features x are normalized to   \\(\\bm{x} \\in [0,1] \\)  . Then the Quantum states are prepared as following:\nAmplitude encoding\n \\( x \\in\\{0,1\\}^{n} \\rightarrow |x \\rangle \\)   This of cause also works when working with binary input features, then it is called Basis encoding Amplitude embedding gives rise to a linear kernel in feature Hilbert space 3 and while it is considered memory efficient, unfortunately ,the depth of this encoder circuit is expected to scale exponentially with the number of qubits for generic inputs. Therefore, algorithms based on amplitude encoding could be impeded by our inability to coherently load data into quantum states. 2\nProduct encoding #  Here, the initial states of the qubits are fixed, e.g. to  \\(|0\\rangle\\)  Product encoding\n \\( x \\in \\mathbb{R}^{N} \\rightarrow\\left|\\psi_{x}\\right\\rangle=\\cos \\left(x_{j}\\right)|0\\rangle\u0026#43;\\sin \\left(x_{j}\\right)|1\\rangle \\)   Product encoding gives rise to highly non-linear kernels in feature Hilbert space. This poses a greater challenge to the optimizer later on.\nEmbedding circuit #  Since the data is normalized and centered ( \\(\\bm{x} \\in [-0.5, 0.5] \\)  ) first a feature map  \\(\\phi(\\bm{x}) = 2*\\pi*\\bm{x} \\)  is applied.\n   \u0026ldquo;Each component of the feature-vector x is embedded as a single qubit rotation  \\( R_{x}(\\phi(x_{i}))\\)  with  \\(\\phi : x \\rightarrow [0,2\\pi)\\)  . As we work with two-dimensional data, we duplicate x0 and x1 on x2 and x3. After embedding the data in the parameters of the  \\(R_{x}\\)  gates, we apply a set of constant  \\(R_{y}\\)  and  \\(R_{z}\\)  rotations. That ensures that if projected down onto the computational basis states, the output states span approximately the same range.\u0026ldquo; 1\n Why the features are embedded twice #   \u0026ldquo;The no-cloning principle of quantum mechanics suggests that there is an advantage in redundantly encoding the input value several times.\u0026ldquo; 4\n The Authors call this \u0026ldquo;input redundancy\u0026rdquo;, in our example the redundancy is n=2. Furthermore the authors conclude that\n \u0026ldquo;Input redundancy must be present if good approximations of functions are the goal\u0026rdquo;\n Code #  @qml.template def statepreparation(x): qml.RX(x[0], wires=0) qml.RX(x[1], wires=1) qml.RX(x[0], wires=2) qml.RX(x[1], wires=3) qml.RY(np.pi / 4, wires=0) qml.RY(np.pi / 4, wires=1) qml.RY(np.pi / 4, wires=2) qml.RY(np.pi / 4, wires=3) qml.RZ(np.pi / 4, wires=0) qml.RZ(np.pi / 4, wires=1) qml.RZ(np.pi / 4, wires=2) qml.RZ(np.pi / 4, wires=3) Sources #  1: Evaluation of Parameterized Quantum Circuits: on the design, and the relation between classification accuracy, expressibility and entangling capability, arXiv:2003.09887  2: Parameterized quantum circuits as machine learning models, arXiv:1906.07682  3: Quantum machine learning in feature Hilbert spaces, arXiv:1803.07128  4: Input Redundancy for Parameterized Quantum Circuits, arXiv:1901.11434 \n"});index.add({'id':5,'href':'/docs/Table-of-contents/5.-Parametrized-Quantum-Circuit/','title':"5. Parametrized Quantum Circuit",'content':"Parameterized Quantum Circuit #  The basic idea of quantum computing is similar to that of kernel methods in machine learning, to efficiently perform computations in an intractably large Hilbert/Kernel space.\nParameterized Quantum Circuits (PQCs, also sometimes referred to as \u0026ldquo;ansatz\u0026rdquo; or \u0026quot; variational quantum circuit\u0026rdquo;) are a combination of multiple quantum gates operating on one or multiple qubits. The quantum gates have free parameters which can be optimized to fit a desired probability distribution.\nSimilar to the universal approximation theorem in neural networks, there always exists a quantum circuit that can represent a target function within an arbitrary small error. The caveat is that such a circuit may be exponentially deep and therefore impractical. 2\nThere are several ways to construct non-linear operations in quantum circuits, both coherently (i.e., exploiting entanglement or measuring) or non-coherently (e.g., exploiting the natural coupling of the system to the environment (Noise)).\nThe circuits presented here and investigated in Hubregtsen et al. 1 were originally proposed by Sim et al. 5\nCircuit 1 #  Circuit number 1 consists of a set of Rx and Rz gates. It is not using any two qubit operations and therefore does not project the input state into a higher dimensional space. This circuit is characterized as having lower expressive power.\n  @qml.qnode(dev) def circuit_01(weights, angles=None): ###################### ##### CIRCUIT 01 ##### ###################### statepreparation(angles) for W in weights: qml.RX(W[0], wires=0) qml.RX(W[1], wires=1) qml.RX(W[2], wires=2) qml.RX(W[3], wires=3) qml.RZ(W[4], wires=0) qml.RZ(W[5], wires=1) qml.RZ(W[6], wires=2) qml.RZ(W[7], wires=3) return qml.probs(wires=[0, 1, 2, 3]) Multiples of these circuits can joined together, like layers in a neural network, where the output of the current layer serves as input for the next one. In the code snippet above, the number of layers is controlled by the number of dimensions in the parameter array W. However,the expressiveness of this circuit is not significantly increased when using a higher number of layers.\nCircuit 19 #  Circuit number 19 was constructed for the task of data classification. It consists of the same set of single rotation gates as circuit number 1 and is extended by a set of controlled Rx gates. The design criteria of the circuit is to generate a highly entangled state which allows an efficient projection of the data into a space where it can be separated. Additionally, it has been shown that this circuit group can identify correlations in the input data.\n  @qml.qnode(dev) def circuit_19(weights, angles=None): ###################### ##### CIRCUIT 19 ##### ###################### statepreparation(angles) for W in weights: qml.RX(W[0], wires=0) qml.RX(W[1], wires=1) qml.RX(W[2], wires=2) qml.RX(W[3], wires=3) qml.RZ(W[4], wires=0) qml.RZ(W[5], wires=1) qml.RZ(W[6], wires=2) qml.RZ(W[7], wires=3) qml.CRX(W[8], wires=[3, 0]) qml.CRX(W[9], wires=[2, 3]) qml.CRX(W[10], wires=[1, 2]) qml.CRX(W[11], wires=[0, 1]) return qml.probs(wires=[0, 1, 2, 3]) Note that the performance of Circuit 19 dies increase with additional layers, as we will see in the results later.\nSources #  1: Evaluation of Parameterized Quantum Circuits: on the design, and the relation between classification accuracy, expressibility and entangling capability, arXiv:2003.09887  2: Parameterized quantum circuits as machine learning models, arXiv:1906.07682  5: Expressibility and entangling capability of parameterized quantum circuits for hybrid quantum-classical algorithms, arXiv:1905.10876 \n"});index.add({'id':6,'href':'/docs/Table-of-contents/6.-Measurement/','title':"6. Measurement",'content':"Measurement #  The four qubits are then measured in a fixed but arbitrary basis. Arbitrary since you can always rotate into a different basis, in this case this rotation is just leaned and not explicitly applied.\nThe process of preparing quantum states, embedding data, applying rotations according to the parameter vector theta and measuring the outcome are performed multiple times.\ndev = qml.device(\u0026#34;default.qubit\u0026#34;, wires=4, shots=1000) This is referred to as \u0026ldquo;shots\u0026rdquo; and will lead to a probability distribution over the possible states.\n  Since this page was quite short, here is some Futurama:\n (Data will be transmitted to Youtube if you watch this video!)   "});index.add({'id':7,'href':'/docs/Table-of-contents/7.-Mapping/','title':"7. Mapping",'content':"Mapping #  Now that we have the probability distribution we need to somehow map this to either one of our output labels. This is done via a boolean function;\nWhen measuring n qubits:   \\( j \\in \\{0,1\\}^{n} \\)  , the mapping function is of the kind:\nboolean mapping function\n \\( j \\rightarrow \\{0,1\\} \\)   While this would be sufficient for a classification task, in order to display the \u0026ldquo;confidence\u0026rdquo; of the prediction, my approach was to multiply the normalized maximum probability (e.g. the value of the highest bar in the histogram) and multiplied it with its label. Only doing that can the squared loss be used as a loss function.\n  Note, that it should technically be indifferent which mapping function is chosen, since the optimizer will just try to learn this arbitrary probability distribution. However, to archive the results presented in the paper, this was the closest mapping function I could find. Also, presumably there are distributions which are \u0026ldquo;harder\u0026rdquo; to learn than others.\n"});index.add({'id':8,'href':'/docs/Table-of-contents/8.-Loss/','title':"8. Loss",'content':"Loss function #  The task of learning an arbitrary function from data is mathematically expressed as the minimization of a loss function   \\(L(\\bm{\\theta})\\)  , also known as the objective function, with respect to the parameter vector  \\(\\bm{\\theta}\\)  For the loss function, a standard quadratic loss was used:\nSquare loss\n \\(L(\\bm{\\theta}) = (y - ŷ)^{2}\\)   Where y is the ground truth label and ŷ is the predicted label\nNote that this only works since we are using the confidence multiplied by its label and not the binary label itself. If we wished to do that, we would have to use a different loss function, e.g. binary cross entropy loss.\n"});index.add({'id':9,'href':'/docs/Table-of-contents/9.-Optimization/','title':"9. Optimization",'content':"Weights are initialized to small random values\nOptimization #  As stated before, the goal of the optimizer is to minimize the loss function. It does this by changing the parameters of the Quantum circuit or neural network. However, a key difference is that it is impossible to access the quantum state at intermediate points during computation. Any attempt to observe the full state of the system would disrupt its quantum character. Moreover, it is difficult to conceive a circuit learning algorithm that truly resembles backpropagation, as it would rely on storing the intermediate state of the network during computation. Backpropagation is the gold standard algorithm for neural networks and can be described as a computationally efficient organization of the chain rule that allows gradient descent to work on large-scale models.\nWhile backprop-like algorithms have been proposed ( Backwards Quantum Propagation of Phase errors (Baqprop) 6), here we will make use of a simpler approach.\nIn the following video, you can see the optimization process, both for a parameterized quantum circuit (left) and a classical neural network (right).\n Your browser does not support the video tag.   Notice that for the PQC the optimization landscape is much more complex. Notice also that the changes between frames decreases towards the end, as the learning rate decreases as well. Parameter-shift rule #  Initially, the parameters are set to small, random values. By evaluating or circuit \u0026ldquo;a little to the left\u0026rdquo; and \u0026ldquo;a little to the right\u0026rdquo; of each parameter, the gradient can be estimated locally (estimation, because while the parameter shift rule is exact for arbitrarily small deltas, we can only execute the circuit a finite amount of times): parameter shift rule\n  \\( \\frac{\\partial L}{\\partial \\theta_{j}} \\approx \\frac{L(\\boldsymbol{\\theta}\u0026#43;c \\boldsymbol{\\Delta})-L(\\boldsymbol{\\theta}-c \\boldsymbol{\\Delta})}{2 c \\Delta_{j}} \\)   where ∆ is a (small) hyperparameter and ej is the Cartesian unit vector in the j direction. Note that while this works, it is extremely inefficient: computes an approximate gradient vector with two evaluations of the loss function PER PARAMETER times the specified number of finite iterations (\u0026ldquo;shots\u0026rdquo;):\n \\( 2 * \\#Params * \\#Shots \\)  Surely, there is a more efficient way to do this?\nSPSA #  Simultaneous perturbation stochastic approximation only requires two evaluations of the loss function, times the number of iterations.\n \\( 2 * \\#Shots \\)  SPSA\n \\( \\frac{\\partial L}{\\partial \\theta_{j}} \\approx \\frac{L\\left(\\boldsymbol{\\theta}\u0026#43;\\Delta \\boldsymbol{e}_{j}\\right)-L\\left(\\boldsymbol{\\theta}-\\Delta \\boldsymbol{e}_{j}\\right)}{2 \\Delta} \\)   where  \\( \\bm{\\Delta} \\)  is a random perturbation vector and  \\(c\\)  is a (small) hyperparameter. So essentially we do not evaluate the gradient for each dimension independently, but joined.\nThere are cases when finite difference methods are ill-conditioned and unstable due to truncation and round-off errors. This is one of the reasons why machine learning relies on the analytical gradient when possible, and it is often calculated with automatic differentiation scheme. Compared to finite difference and SPSA, the analytical gradient has the advantage of providing an unbiased estimator. 2\n(Stochastic) Gradient descent #  Now, that we have obtained a gradient vector through either method, we need to use it to update the circuit\u0026rsquo;s parameters. In the realm of classical optimization gradient descent and it\u0026rsquo;s derived methods have proven to be efficient and powerful at optimization tasks.\nGradient descent update rule\n \\( \\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta}-\\eta \\nabla_{\\boldsymbol{\\theta}} L \\)   Where  \\(\\nabla_{\\boldsymbol{\\theta}} L\\)  is the gradient vector and  \\(\\eta\\)  is the learning rate. This update rule is then applied iteratively.\nFor stochastic gradient descent, instead of calculating the gradients over the whole training set, gradients are only calculated for an i.i.d. subsampeled \u0026ldquo;minibatch\u0026rdquo;.\nThere are further practical \u0026ldquo;tricks\u0026rdquo; to facilitate training, which shall be outlined shortly:\nMinibatches #  In this implementation a minibach size of 265 was used, which seems relatively large to me, but provided the most stable results. In the paper, the the batch size is not mentioned.\nLearning rate schedule #  Instead of using the same learning rate throughout, larger steps are taken in the beginning and smaller steps in the end. This is done via learning rate schedule, decreasing the learning rate every X number of epochs.\nADAM #  There are further improvements to stochastic gradient descent namely ADAM, which uses first and second order momentum to overcome plateaus. If you are not familiar, head over to Wikipedia.\nTalk is cheap, show me the code - Linus Torvalds #  Luckily pennylane already comes with interfaces for lots of different opimizers, such as NumPy, Pytorch and Tensorflow. As stated above, the ADAM optimizer from NumPy will be used.\nfrom pennylane.optimize import AdamOptimizer num_qubits = 4 num_layers = 2 qc= c19(num_layers) num_params = qc.get_numparams() best_val = (0.01 * np.random.randn(num_layers, num_params), 0.01) best_acc = 0.0 learning_rate = [4,2,1,0.5,0.25,0.1] opt = AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999) Furthermore, pennylane also comes with an array of differentiation methods:\n  \u0026ldquo;best\u0026rdquo;: Best available method. Uses classical backpropagation or the device directly to compute the gradient if supported, otherwise will use the analytic parameter-shift rule where possible with finite-difference as a fallback.\n  \u0026ldquo;backprop\u0026rdquo;: Use classical backpropagation. Only allowed on simulator devices that are classically end-to-end differentiable, for example default.tensor.tf. Note that the returned QNode can only be used with the machine learning framework supported by the device; a separate interface argument should not be passed.\n  \u0026ldquo;device\u0026rdquo;: Queries the device directly for the gradient. Only allowed on devices that provide their own gradient rules.\n  \u0026ldquo;parameter-shift\u0026rdquo;: Use the analytic parameter-shift rule where possible, with finite-difference as a fallback.\n  \u0026ldquo;finite-diff\u0026rdquo;: Uses numerical finite-differences for all parameters.\n  None: a non-differentiable QNode is returned.\n  I have used the \u0026ldquo;best method throughout, while the paper 1 uses SPSA.\nlosslist = [] batch_size = 256 # train the variational classifier var = best_val#var_init for lr in learning_rate: opt = AdamOptimizer(lr, beta1=0.9, beta2=0.999) for it in range(60): # Draw minibatch batch_index = np.random.randint(0, num_train, (batch_size,)) feats_train_batch = feats_train[batch_index] Y_train_batch = Y_train[batch_index] var = opt.step(lambda v: qc.cost(v, feats_train_batch, Y_train_batch), var) # Compute predictions on train and validation set predictions_train = [np.sign(qc.variational_classifier(var, angles=f)) for f in feats_train] predictions_val = [np.sign(qc.variational_classifier(var, angles=f)) for f in feats_val] # Compute accuracy on train and validation set acc_train = accuracy(Y_train, predictions_train) acc_val = accuracy(Y_val, predictions_val) if acc_train \u0026gt; best_acc: print(\u0026#34;NEW BEST\u0026#34;) best_val = var best_acc = acc_train loss = qc.cost(var, features, Y) losslist.append(loss) print( \u0026#34;Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} | Best acc: {:0.7f}\u0026#34; \u0026#34;\u0026#34;.format(it + 1, loss, acc_train, acc_val, best_acc) ) Training time #  Training a single data set on circuit19 took about 5 hours. For the 9 sets that\u0026rsquo;s almost two whole days! Training the classical Neural network on a single data set to a similar accuracy takes about 5 minutes\u0026hellip;\nSources #  1: Evaluation of Parameterized Quantum Circuits: on the design, and the relation between classification accuracy, expressibility and entangling capability, arXiv:2003.09887  2: Parameterized quantum circuits as machine learning models, arXiv:1906.07682  6: A Universal Training Algorithm for Quantum Deep Learning, arXiv:1806.09729 \n"});index.add({'id':10,'href':'/docs/Table-of-contents/ZZZ/','title':"10. Results",'content':"Results #  Be aware, that the results might not line up exactly for different reasons. After all this is a stochastic optimization process, the generation of the Data, the selection of training and validation set or the selection of the minibatches might contribute to finding a different minima.\nQuantum circuit results comparison #  The following images show the decision boundaries for circuit 19 with two layers. I tweaked the batch size and the learning rate, thereby increasing the optimization duration but archiving much more consistent results. Note how 3b is especially close to the paper\u0026rsquo;s result: My results   Batch size: 256\nlearning rate schedule: [4,2,1,0.5,0.25,0.1]\n# of epochs per learning rate: 60\n Theirs   Batch size: ???\nLearning rate schedule: [4,3,2,1.5,1,0.5]\n# of epochs per learning rate: 30\n  Here are my results again, this time with confidence values:\n  Notice that the only obvious poor result is visible for 3c. The generalization is really bad, to which the high class imbalance and thus comparatively low number of red training examples probably contributed. Interestingly the confidence in either class is also rather low in this data set. My theory is, that once a low classification error is archived, the only way to minimize the loss function is to increase the confidence in the classification.\nNeural Network results comparison #  The following images show the decision boundaries for the neural network with two layers. In the paper no information about the actual optimization procedure, besides the use of ADAM are given. So despite having to reverse engineer most of the parameters, I think the results are reasonably close. Here you can see the comparison of the two layer networks.\nMy results    Theirs     Quantum circuit vs Neural Network #  My Quantum circuit result    My classical NN result     Accuracy scores #   .tg {border-collapse:collapse;border-spacing:0;} .tg td{border-bottom-width:1px;border-color:black;border-style:solid;border-top-width:1px;border-width:0px; font-family:Arial, sans-serif;font-size:10px;overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{border-bottom-width:1px;border-color:black;border-style:solid;border-top-width:1px;border-width:0px; font-family:Arial, sans-serif;font-size:10px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-glna{background-color:#fffe65;text-align:left;vertical-align:top} .tg .tg-0lax{text-align:left;vertical-align:top} .tg .tg-tf2e{text-align:left;vertical-align:top} .tg .tg-f0m5{background-color:#fffe65;text-align:left;vertical-align:top}    Setup Performance     Type Alg. 1a 1b 1c 2a 2b 2c 3a 3b 3c Average   Classical NN - 2l 96% 100% 100% 100% 99% 98% 100% 99% 97% 99%   Classical (mine) NN - 2l 95% 100% 100% 100% 96% 87% 100% 98% 94% 97%   Hybrid c19 - 2l 95% 97% 84% 91% 94% 74% 93% 91% 87% 90%   Hybrid (mine) c19 - 2l 95% 99% 98% 100% 99% 98% 96% 97% 80% 95%     Conclusion #   Hybrid learning will be a powerful technique on near term noisy quantum computers To date, all supervised learning experiments involved scaled-down, often trivial, data sets due to the limitation of available quantum hardware, and demonstrations at a more realistic scale are desirable. One possible pitfall is that as the circuits become more expressive, the optimization landscape might also become harder to explore. Provided that we can efficiently load or prepare quantum data in a qubit register, PQC models will deliver a clear advantage over classical methods for quantum learning tasks.  Outlook #  What now?\n Have a look at the code and try it yourself! Try a different initialization scheme to avoid barren plateaus Try combinations of different circuits, layers, embedding or cost functions! Try different optimizers, such as gradient free optimizers (e.g. genetic algorithms) of try an analytical gradient! Try regularization! Try to find a real-world data set! Go deeper!  "});index.add({'id':11,'href':'/docs/Table-of-contents/','title':"Table of Contents",'content':""});index.add({'id':12,'href':'/docs/','title':"Docs",'content':""});})();