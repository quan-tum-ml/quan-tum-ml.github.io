<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>‚öõÔ∏èHybrid Quantum Classical Machine LearningüîÆ</title>
    <link>https://www.qu.antum.ml/docs/Table-of-contents/</link>
    <description>Recent content on ‚öõÔ∏èHybrid Quantum Classical Machine LearningüîÆ</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://www.qu.antum.ml/docs/Table-of-contents/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/0.-Preface/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/0.-Preface/</guid>
      <description>What are Hybrid networks, anyway? #  While looking through the web, it seemed there is no clear-cut definition of &amp;ldquo;Hybrid&amp;rdquo;.
  This Qiskit tutorial uses a classical Neural network to learn the optimal rotations for a simple quantum circuit.
  This Tensorflow Quantum tutorial uses something akin to a regular max-pooling layer to first downproject the 28x28 images to 4x4 images, which are then fed into a qubit grid of same size.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/1.-Introduction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/1.-Introduction/</guid>
      <description>Environment setup #  There is actually a suprisingly large amount of different libraries for quantum state simulation. I will use pennylane by XANADU.
Qiskit
Tensorflow Quantum
Cirq
Virtual env #  Getting started #  https://pennylane.ai/qml/demos/tutorial_variational_classifier.html</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/2.-The-Data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/2.-The-Data/</guid>
      <description>About the Data #  This synthetic set consists of three subsets, each with three increasing difficulty levels, amounting to 9 datasets in total. Each of the nine sets consists of 1500 points (the amount is specified during the data generation). The data are split into 70% train and 30% validation.
  Screenshot from  1
*Note that the Datasets are nomalized to length one, but not centered around zero.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/3.-Architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/3.-Architecture/</guid>
      <description>Architecture #  Quantum Circuit #  I shall quickly describe the individual components which will be explained in greater detail on the following pages. Here the hybrid aspect becomes obvious: Blue background represents a quantum computer based system, while gray background represents a classical computer system.
   The Data: synthetic, two-dimensional data, normalized and centered. Embedding: encodes the data into quantum states. Parametrized Quantum Circuit: Performs rotations and controlled rotations on qubits according to the parametervecor theta.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/4.-Embedding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/4.-Embedding/</guid>
      <description>How does one get the data into the Quantum circuit? #  There are a multitude of ways to do so. The two simplest ways to embed information are Amplitude and Product encoding. This embedding circuit preceeds all other quantum circuits shown later and will not be drawn explicitly.
TODO: talk about scaling&amp;hellip;linear vs. non-linear kernel
Amplitude encoding #  Amplitude encoding only works if the input features x are nomalized to   \(\bm{x} \in [0,1] \)  .</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/5.-Parametrized-Quantum-Circuit/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/5.-Parametrized-Quantum-Circuit/</guid>
      <description>TODO #  The basic idea of quantum computing is similar to that of kernel methods in machine learning, to efficiently perform computations in an intractably large Hilbert/Kernel space.
Parameterized Quantum Circuits (PQCs, also sometimes referred to as &amp;ldquo;ansatz&amp;rdquo; or &amp;quot; variational quantum circuit&amp;rdquo;) are a combination of multiple quantum gates operating on one or multiple qubits. The quantum gates have free parameters which can be optimzied to fit a desired probability distribution.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/6.-Measurement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/6.-Measurement/</guid>
      <description>Measurement #  The four qubits are then measured in a fixed but arbitray basis. Arbitrary since you can always rotate into a different basis, in this case this rotation is just leaned and not explicitly applied.
The process of preparing quantum states, embedding data, applying rotations according to the parametervecor theta and measureing the outcome are performed muliple times.
dev = qml.device(&amp;#34;default.qubit&amp;#34;, wires=4, shots=1000) This is referred to as &amp;ldquo;shots&amp;rdquo; and will lead to a probability distribution over the possible states.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/7.-Mapping/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/7.-Mapping/</guid>
      <description>Mapping #  Now that we have the probabl√≠lity distribution we need to somehow map this to eighter one of our output labels. This is done via a boolean function;
When measureing n qubits:   \( j \in \{0,1\}^{n} \)  , the mapping function is of the kind:
boolean mapping function
 \( j \rightarrow \{0,1\} \)   While this would be sufficient for a classification task, in order to display the &amp;ldquo;confidence&amp;rdquo; of the prediction, my approach was to multiply the normalized maximum probability (e.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/8.-Loss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/8.-Loss/</guid>
      <description>Ubi loqui #  The task of learning an arbitrary function from data is mathematically expressed as the minimization of a loss function   \(L(\bm{\theta})\)  , also known as the objective function, with respect to the parameter vector  \(\bm{\theta}\)  For the loss function, a standart quadratic loss was used:
Square loss
 \(L(\bm{\theta}) = (y - ≈∑)^{2}\)   Where y is the ground truth label and ≈∑ is the predicted label</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/9.-Optimization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/9.-Optimization/</guid>
      <description>Optimization #  SPSA
  \( \frac{\partial L}{\partial \theta_{j}} \approx \frac{L\left(\boldsymbol{\theta}&amp;#43;\Delta \boldsymbol{e}_{j}\right)-L\left(\boldsymbol{\theta}-\Delta \boldsymbol{e}_{j}\right)}{2 \Delta} \)   Gradient descent
 \( \frac{\partial L}{\partial \theta_{j}} \approx \frac{L(\boldsymbol{\theta}&amp;#43;c \boldsymbol{\Delta})-L(\boldsymbol{\theta}-c \boldsymbol{\Delta})}{2 c \Delta_{j}} \)   ADAM
 \( \boldsymbol{\theta} \leftarrow \boldsymbol{\theta}-\eta \nabla_{\boldsymbol{\theta}} L \)   num_qubits = 4 num_layers = 2 qc= c19(num_layers) num_params = qc.get_numparams() best_val = (0.01 * np.random.randn(num_layers, num_params), 0.01)#[] best_acc = 0.0 from pennylane.optimize import AdamOptimizer learning_rate = [4,2,1,0.</description>
    </item>
    
    <item>
      <title>10. Results</title>
      <link>https://www.qu.antum.ml/docs/Table-of-contents/ZZZ/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.qu.antum.ml/docs/Table-of-contents/ZZZ/</guid>
      <description>Results #  Be aware, that the results might not line up exactly for different reasons. After all this is a stochastic optimization process, the generation of the Data, the selection of training and validation set or the selection of the minibatches mitght contribute to finding a different minima.
Quantum circuit results comparison #  The following images show the decision boundaries for circuit 19 with two layers. I tweaked the batch size and the learning rate, thereby increasing the optimization duration but archieving much more consistent results.</description>
    </item>
    
  </channel>
</rss>